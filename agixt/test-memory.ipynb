{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:09:51,853 | INFO | Running Chroma using direct local API.\n",
      "2023-05-31 09:09:51,854 | WARNING | Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from Agent import Agent\n",
    "from semantic_kernel.connectors.memory.chroma import ChromaMemoryStore\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "\n",
    "agent_name = \"OpenAI\"\n",
    "agent = Agent(agent_name=agent_name)\n",
    "agent_config = agent.agent_config\n",
    "embedder, chunk_size = await agent.get_embedder()\n",
    "memories_dir = f\"{os.getcwd()}/agents/{agent_name}/memories/\"\n",
    "chroma_client = ChromaMemoryStore(\n",
    "    client_settings=Settings(\n",
    "        chroma_db_impl=\"duckdb\",\n",
    "        persist_directory=memories_dir,\n",
    "        anonymized_telemetry=False,\n",
    "    ),\n",
    "    persist_directory=memories_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chroma_client.does_collection_exist_async(\"memories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:09:45,533 | INFO | Exiting: Cleaning up .chroma directory\n"
     ]
    }
   ],
   "source": [
    "memories_exist = await chroma_client.does_collection_exist_async(\"memories\")\n",
    "if not memories_exist:\n",
    "    await chroma_client.create_collection_async(collection_name=\"memories\")\n",
    "    memories = await chroma_client.get_collection_async(collection_name=\"memories\")\n",
    "else:\n",
    "    memories = await chroma_client.get_collection_async(collection_name=\"memories\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 08:58:33,272 | INFO | message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=313 request_id=c599172dae99ca6fb4216ffd718eedfc response_code=200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1b722caa2575a95c56336cd950d6fa694d5670b54834a3d3d9794a7d08d8642c'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hashlib import sha256\n",
    "from datetime import datetime\n",
    "from semantic_kernel.memory.memory_record import MemoryRecord\n",
    "\n",
    "description = \"Test memory\"\n",
    "external_source_name = \"Test memory\"\n",
    "content = \"Test memory\"\n",
    "\n",
    "record = MemoryRecord(\n",
    "    is_reference=False,\n",
    "    id=sha256((content + datetime.now().isoformat()).encode()).hexdigest(),\n",
    "    text=content,\n",
    "    timestamp=datetime.now().isoformat(),\n",
    "    description=description,\n",
    "    external_source_name=external_source_name,  # URL or File path\n",
    "    embedding=await embedder(content),\n",
    ")\n",
    "\n",
    "await chroma_client.upsert_async(\n",
    "    collection_name=\"memories\",\n",
    "    record=record,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 08:58:35,371 | INFO | message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=31 request_id=6f68dca8730eeb3c133357e46dfdce36 response_code=200\n"
     ]
    }
   ],
   "source": [
    "results = await chroma_client.get_nearest_matches_async(\n",
    "    collection_name=\"memories\",\n",
    "    embedding=await embedder(content),\n",
    "    limit=1,\n",
    "    min_relevance_score=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test memory']\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "for memory, score in results:\n",
    "    context.append(memory._text)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Memories' object has no attribute 'get_embedder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m content \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTest memory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mawait\u001b[39;00m agent\u001b[39m.\u001b[39mmemories\u001b[39m.\u001b[39mcontext_agent(query\u001b[39m=\u001b[39mcontent, top_results_num\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/josh/Repos/AGiXT/agixt/Memories.py:102\u001b[0m, in \u001b[0;36mMemories.context_agent\u001b[0;34m(self, query, top_results_num)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mcontext_agent\u001b[39m(\u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m, top_results_num: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 102\u001b[0m     embedder, chunk_size \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_embedder()\n\u001b[1;32m    103\u001b[0m     collection \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_memories()\n\u001b[1;32m    104\u001b[0m     \u001b[39mif\u001b[39;00m collection \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Memories' object has no attribute 'get_embedder'"
     ]
    }
   ],
   "source": [
    "content = \"Test memory\"\n",
    "\n",
    "await agent.memories.context_agent(query=content, top_results_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 08:15:38,537 | INFO | message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=260 request_id=ed358be9efe6983fe6b50d7bdd795660 response_code=200\n"
     ]
    }
   ],
   "source": [
    "# Store a memory\n",
    "await memories.store_memory(content=\"Test memory\", description=\"Test memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 08:16:04,802 | INFO | Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "2023-05-31 08:16:04,803 | INFO | Running Chroma using direct local API.\n",
      "2023-05-31 08:16:04,803 | WARNING | Using embedded DuckDB with persistence: data will be stored in: /home/josh/josh/Repos/AGiXT/agixt/agents/OpenAI/memories\n",
      "2023-05-31 08:16:04,806 | INFO | No existing DB found in /home/josh/josh/Repos/AGiXT/agixt/agents/OpenAI/memories, skipping load\n",
      "2023-05-31 08:16:04,806 | INFO | No existing DB found in /home/josh/josh/Repos/AGiXT/agixt/agents/OpenAI/memories, skipping load\n",
      "2023-05-31 08:16:04,807 | INFO | Memories for OpenAI do not exist. Creating...\n",
      "2023-05-31 08:16:05,417 | INFO | message='OpenAI API response' path=https://api.openai.com/v1/embeddings processing_ms=435 request_id=7e2931cce94d959f8849805ff50cfb62 response_code=200\n",
      "2023-05-31 08:16:05,423 | INFO | Failed to get context: Index not found, please create an instance before querying\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await memories.context_agent(query=content, top_results_num=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
