{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AgentLLM import AgentLLM\n",
    "\n",
    "\n",
    "def smart_instruct(\n",
    "    agent_name: str = \"huggingchat\",\n",
    "    user_input: str = \"Write a tweet about AI.\",\n",
    "    shots: int = 3,\n",
    "):\n",
    "    agent = AgentLLM(agent_name)\n",
    "    prompt = f\"Functions Available To Complete Task: {{COMMANDS}}\\n\\nContext: {{context}}\\n\\nTask: {user_input}\\nAnswer: Let's work this out in a step by step way to be sure we are doing what is asked.\"\n",
    "    answers = []\n",
    "    # Do 3 shots of prompt to get 3 different answers\n",
    "    for i in range(shots):\n",
    "        answers.append(agent.run(task=prompt))\n",
    "    validation_prompt = f\"You are a reasearcher task with investigating the {shots} response options provided. List the flaws and faulty logic of each answer option. Lets work this out in a step by step way to be sure we have all the errors.\\n\\n\"\n",
    "    for i, answer in enumerate(answers):\n",
    "        validation_prompt += f\"Answer {i + 1}:\\n{answer}\\n\\n\"\n",
    "    validation = agent.run(task=validation_prompt)\n",
    "    resolver_prompt = f\"You are a resolver tasked with 1) Finding which of the {shots} answer options the researcher thought was best 2) improving that answer, and 3) Printing the improved answer in full.  Let's work this out in a step by step way to be sure we have the right answer:\\n\\n{validation}\"\n",
    "    resolver = agent.run(task=resolver_prompt)\n",
    "    return resolver"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
