{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests for AGiXT API Client\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Providers\n",
    "\n",
    "This will get a list of AI providers available to use with AGiXT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers: ['gpt4free', 'azure', 'chatgpt', 'runpod', 'oobabooga', 'openai', 'huggingface', 'fastchat', 'transformer', 'bing', 'palm', 'claude', 'gpt4all', 'huggingchat', 'llamacppapi', 'kobold', 'llamacpp', 'gpugpt4all', 'bard']\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_providers()\n",
    "providers = ApiClient.get_providers()\n",
    "print(\"Providers:\", providers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Default Provider Settings\n",
    "\n",
    "Choose a provider from the list of AI providers and get the default settings for that provider.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings for gpt4free: {'AI_MODEL': 'gpt-3.5-turbo', 'AI_TEMPERATURE': 0.7, 'MAX_TOKENS': 4000, 'provider': 'gpt4free'}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_provider_settings()\n",
    "provider_name = \"gpt4free\"\n",
    "provider_settings = ApiClient.get_provider_settings(provider_name=provider_name)\n",
    "print(f\"Settings for {provider_name}:\", provider_settings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Embedding Providers\n",
    "\n",
    "Embedding providers are used to embed information to vectors to store in the vector database to be searched for context injection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed Providers: ['azure', 'cohere', 'default', 'embed_text', 'get_embedder', 'google_palm', 'google_vertex', 'large_local', 'llamacpp', 'openai']\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_embed_providers()\n",
    "embed_providers = ApiClient.get_embed_providers()\n",
    "print(\"Embed Providers:\", embed_providers)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Extension Settings\n",
    "\n",
    "This is where we get all third party extension settings for the agent with defaults to fill in when there is nothing entered on the front end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extension Settings response: {'macostts': {'USE_MAC_OS_TTS': False}, 'file_system': {'WORKING_DIRECTORY': './WORKSPACE', 'WORKING_DIRECTORY_RESTRICTED': True}, 'huggingface': {'HUGGINGFACE_API_KEY': '', 'HUGGINGFACE_AUDIO_TO_TEXT_MODEL': 'facebook/wav2vec2-large-960h-lv60-self', 'WORKING_DIRECTORY': './WORKSPACE'}, 'discord': {'DISCORD_API_KEY': '', 'DISCORD_COMMAND_PREFIX': '/AGiXT'}, 'dalle': {'HUGGINGFACE_API_KEY': '', 'OPENAI_API_KEY': '', 'WORKING_DIRECTORY': './WORKSPACE'}, 'briantts': {'USE_BRIAN_TTS': True}, 'google': {'GOOGLE_API_KEY': ''}, 'microsoft_365': {'MICROSOFT_365_CLIENT_ID': '', 'MICROSOFT_365_CLIENT_SECRET': '', 'MICROSOFT_365_REDIRECT_URI': ''}, 'github': {'GITHUB_USERNAME': '', 'GITHUB_API_KEY': '', 'WORKING_DIRECTORY': './WORKSPACE'}, 'gtts': {'USE_GTTS': False}, 'elevenlabs': {'ELEVENLABS_API_KEY': '', 'ELEVENLABS_VOICE': 'Josh'}, 'sendgrid_email': {'SENDGRID_API_KEY': '', 'SENDGRID_EMAIL': ''}, 'searxng': {'SEARXNG_INSTANCE_URL': ''}, 'twitter': {'TW_CONSUMER_KEY': '', 'TW_CONSUMER_SECRET': '', 'TW_ACCESS_TOKEN': '', 'TW_ACCESS_TOKEN_SECRET': ''}}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_extension_settings()\n",
    "ext_settings_resp = ApiClient.get_extension_settings()\n",
    "print(\"Extension Settings response:\", ext_settings_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Extension Commands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions response: [['Scrape Text with Playwright', 'scrape_text_with_playwright', {'url': None}], ['Scrape Links with Playwright', 'scrape_links_with_playwright', {'url': None}], ['Speak with MacOS TTS', 'speak_with_macos_speech', {'text': None, 'voice_index': 0}], ['Evaluate Code', 'evaluate_code', {'code': None, 'agent': 'AGiXT'}], ['Analyze Pull Request', 'analyze_pull_request', {'pr_url': None, 'agent': 'AGiXT'}], ['Perform Automated Testing', 'perform_automated_testing', {'test_url': None, 'agent': 'AGiXT'}], ['Run CI-CD Pipeline', 'run_ci_cd_pipeline', {'repo_url': None, 'agent': 'AGiXT'}], ['Improve Code', 'improve_code', {'suggestions': None, 'code': None, 'agent': 'AGiXT'}], ['Write Tests', 'write_tests', {'code': None, 'focus': None, 'agent': 'AGiXT'}], ['Create a new command', 'create_command', {'function_description': None, 'agent': 'AGiXT'}], ['Execute Task List', 'execute_task_list', {'agent': None, 'tasks': None, 'user_input': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5}], ['Prompt AI Agent', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Ask AI Agent Bing', 'ask', {'user_input': None, 'agent': 'AGiXT'}], ['Instruct AI Agent Bing', 'instruct', {'user_input': None, 'agent': 'AGiXT'}], ['Prompt AI Agent Bing', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Ask AI Agent gpt4free', 'ask', {'user_input': None, 'agent': 'AGiXT'}], ['Instruct AI Agent gpt4free', 'instruct', {'user_input': None, 'agent': 'AGiXT'}], ['Prompt AI Agent gpt4free', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Ask AI Agent Bard', 'ask', {'user_input': None, 'agent': 'AGiXT'}], ['Instruct AI Agent Bard', 'instruct', {'user_input': None, 'agent': 'AGiXT'}], ['Prompt AI Agent Bard', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Ask AI Agent Vicuna', 'ask', {'user_input': None, 'agent': 'AGiXT'}], ['Instruct AI Agent Vicuna', 'instruct', {'user_input': None, 'agent': 'AGiXT'}], ['Prompt AI Agent Vicuna', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Ask AI Agent OpenAI', 'ask', {'user_input': None, 'agent': 'AGiXT'}], ['Instruct AI Agent OpenAI', 'instruct', {'user_input': None, 'agent': 'AGiXT'}], ['Prompt AI Agent OpenAI', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Ask AI Agent azure', 'ask', {'user_input': None, 'agent': 'AGiXT'}], ['Instruct AI Agent azure', 'instruct', {'user_input': None, 'agent': 'AGiXT'}], ['Prompt AI Agent azure', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Ask AI Agent ChatGPT', 'ask', {'user_input': None, 'agent': 'AGiXT'}], ['Instruct AI Agent ChatGPT', 'instruct', {'user_input': None, 'agent': 'AGiXT'}], ['Prompt AI Agent ChatGPT', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Ask AI Agent Guanaco', 'ask', {'user_input': None, 'agent': 'AGiXT'}], ['Instruct AI Agent Guanaco', 'instruct', {'user_input': None, 'agent': 'AGiXT'}], ['Prompt AI Agent Guanaco', 'prompt_agent', {'user_input': None, 'prompt_name': None, 'prompt_args': None, 'websearch': False, 'websearch_depth': 3, 'context_results': 5, 'shots': 1}], ['Write to File', 'write_to_file', {'filename': None, 'text': None}], ['Read File', 'read_file', {'filename': None}], ['Search Files', 'search_files', {'directory': None}], ['Append to File', 'append_to_file', {'filename': None, 'text': None}], ['Execute Python File', 'execute_python_file', {'file': None}], ['Delete File', 'delete_file', {'filename': None}], ['Execute Shell', 'execute_shell', {'command_line': None}], ['Read Audio from File', 'read_audio_from_file', {'audio_path': None}], ['Read Audio', 'read_audio', {'audio': None}], ['Generate Image with Stable Diffusion', 'generate_image_with_hf', {'prompt': None, 'filename': None}], ['Speak with TTS with BrianTTS', 'speak_with_briantts', {'text': None}], ['Clone Github Repository', 'clone_repo', {'repo_url': None, 'clone_path': None}], ['Get Datetime', 'get_datetime', {}], ['Speak with TTS Using Elevenlabs', 'speak_with_elevenlabs', {'text': None, 'voice_index': 0}], ['Use The Search Engine', 'search', {'query': None}]]\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_extensions()\n",
    "ext = ApiClient.get_extensions()\n",
    "print(\"Extensions response:\", ext)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of all current Agents\n",
    "\n",
    "Any agents that you have created will be listed here. The `status` field is to say if the agent is currently running a task or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agents: [{'name': 'Bing', 'status': False}, {'name': 'gpt4free', 'status': False}, {'name': 'Bard', 'status': False}, {'name': 'Vicuna', 'status': False}, {'name': 'OpenAI', 'status': False}, {'name': 'azure', 'status': False}, {'name': 'ChatGPT', 'status': False}, {'name': 'Guanaco', 'status': False}]\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_agents()\n",
    "agents = ApiClient.get_agents()\n",
    "print(\"Agents:\", agents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new Agent\n",
    "\n",
    "Creates a new agent with the `gpt4free` provider. We'll use `gpt4free` because it is the one that requires the least configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add agent response: {'message': 'Agent test_agent created.'}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test add_agent()\n",
    "agent_name = \"test_agent\"\n",
    "provider_name = \"gpt4free\"\n",
    "# Gets a list of the provider setting defaults\n",
    "# We'll use defaults for the provider instead of defining anything for the tests.\n",
    "provider_settings = ApiClient.get_provider_settings(provider_name=provider_name)\n",
    "add_agent_resp = ApiClient.add_agent(agent_name=agent_name, settings=provider_settings)\n",
    "print(\"Add agent response:\", add_agent_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the test agent\n",
    "\n",
    "We will just rename it to `new_agent`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename agent response: {'message': 'Agent renamed.'}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test rename_agent()\n",
    "agent_name = \"test_agent\"\n",
    "new_agent_name = \"new_agent\"\n",
    "rename_agent_resp = ApiClient.rename_agent(\n",
    "    agent_name=agent_name, new_name=new_agent_name\n",
    ")\n",
    "print(\"Rename agent response:\", rename_agent_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the agent's settings\n",
    "\n",
    "This will get the settings for the agent we just created, this will tell you all commands available to the agent as well as all of the provider settings for the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config for new_agent: {'commands': {'Scrape Text with Playwright': False, 'Scrape Links with Playwright': False, 'Speak with MacOS TTS': False, 'Evaluate Code': False, 'Analyze Pull Request': False, 'Perform Automated Testing': False, 'Run CI-CD Pipeline': False, 'Improve Code': False, 'Write Tests': False, 'Create a new command': False, 'Execute Task List': False, 'Prompt AI Agent': False, 'Ask AI Agent Bing': False, 'Instruct AI Agent Bing': False, 'Prompt AI Agent Bing': False, 'Ask AI Agent gpt4free': False, 'Instruct AI Agent gpt4free': False, 'Prompt AI Agent gpt4free': False, 'Ask AI Agent Bard': False, 'Instruct AI Agent Bard': False, 'Prompt AI Agent Bard': False, 'Ask AI Agent Vicuna': False, 'Instruct AI Agent Vicuna': False, 'Prompt AI Agent Vicuna': False, 'Ask AI Agent OpenAI': False, 'Instruct AI Agent OpenAI': False, 'Prompt AI Agent OpenAI': False, 'Ask AI Agent azure': False, 'Instruct AI Agent azure': False, 'Prompt AI Agent azure': False, 'Ask AI Agent ChatGPT': False, 'Instruct AI Agent ChatGPT': False, 'Prompt AI Agent ChatGPT': False, 'Ask AI Agent new_agent': False, 'Instruct AI Agent new_agent': False, 'Prompt AI Agent new_agent': False, 'Ask AI Agent Guanaco': False, 'Instruct AI Agent Guanaco': False, 'Prompt AI Agent Guanaco': False, 'Write to File': False, 'Read File': False, 'Search Files': False, 'Append to File': False, 'Execute Python File': False, 'Delete File': False, 'Execute Shell': False, 'Read Audio from File': False, 'Read Audio': False, 'Generate Image with Stable Diffusion': False, 'Speak with TTS with BrianTTS': False, 'Clone Github Repository': False, 'Get Datetime': False, 'Speak with TTS Using Elevenlabs': False, 'Use The Search Engine': False}, 'settings': {'AI_MODEL': 'gpt-3.5-turbo', 'AI_TEMPERATURE': 0.7, 'MAX_TOKENS': 4000, 'provider': 'gpt4free'}}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_agentconfig()\n",
    "agent_name = \"new_agent\"\n",
    "agent_config = ApiClient.get_agentconfig(agent_name=agent_name)\n",
    "print(f\"Config for {agent_name}:\", agent_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the agent's settings\n",
    "\n",
    "We'll just update the temperature from the default `0.7` to `0.5` to confirm that we can modify a setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update agent settings response: Agent new_agent configuration updated.\n",
      "New config for new_agent: {'commands': {'Scrape Text with Playwright': False, 'Scrape Links with Playwright': False, 'Speak with MacOS TTS': False, 'Evaluate Code': False, 'Analyze Pull Request': False, 'Perform Automated Testing': False, 'Run CI-CD Pipeline': False, 'Improve Code': False, 'Write Tests': False, 'Create a new command': False, 'Execute Task List': False, 'Prompt AI Agent': False, 'Ask AI Agent Bing': False, 'Instruct AI Agent Bing': False, 'Prompt AI Agent Bing': False, 'Ask AI Agent gpt4free': False, 'Instruct AI Agent gpt4free': False, 'Prompt AI Agent gpt4free': False, 'Ask AI Agent Bard': False, 'Instruct AI Agent Bard': False, 'Prompt AI Agent Bard': False, 'Ask AI Agent Vicuna': False, 'Instruct AI Agent Vicuna': False, 'Prompt AI Agent Vicuna': False, 'Ask AI Agent OpenAI': False, 'Instruct AI Agent OpenAI': False, 'Prompt AI Agent OpenAI': False, 'Ask AI Agent azure': False, 'Instruct AI Agent azure': False, 'Prompt AI Agent azure': False, 'Ask AI Agent ChatGPT': False, 'Instruct AI Agent ChatGPT': False, 'Prompt AI Agent ChatGPT': False, 'Ask AI Agent new_agent': False, 'Instruct AI Agent new_agent': False, 'Prompt AI Agent new_agent': False, 'Ask AI Agent Guanaco': False, 'Instruct AI Agent Guanaco': False, 'Prompt AI Agent Guanaco': False, 'Write to File': False, 'Read File': False, 'Search Files': False, 'Append to File': False, 'Execute Python File': False, 'Delete File': False, 'Execute Shell': False, 'Read Audio from File': False, 'Read Audio': False, 'Generate Image with Stable Diffusion': False, 'Speak with TTS with BrianTTS': False, 'Clone Github Repository': False, 'Get Datetime': False, 'Speak with TTS Using Elevenlabs': False, 'Use The Search Engine': False}, 'settings': {'AI_MODEL': 'gpt-3.5-turbo', 'AI_TEMPERATURE': 0.5, 'MAX_TOKENS': 4000, 'provider': 'gpt4free'}}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test update_agent_settings()\n",
    "agent_name = \"new_agent\"\n",
    "agent_config = ApiClient.get_agentconfig(agent_name=agent_name)\n",
    "agent_settings = agent_config[\"settings\"]\n",
    "# We'll just change the AI_TEMPERATURE setting for the test\n",
    "agent_settings[\"AI_TEMPERATURE\"] = 0.5\n",
    "update_agent_settings_resp = ApiClient.update_agent_settings(\n",
    "    agent_name=agent_name, settings=agent_settings\n",
    ")\n",
    "print(\"Update agent settings response:\", update_agent_settings_resp)\n",
    "agent_config = ApiClient.get_agentconfig(agent_name=agent_name)\n",
    "print(f\"New config for {agent_name}:\", agent_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of the agent's commands\n",
    "\n",
    "This will get a list of all commands available to the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands: {'Scrape Text with Playwright': False, 'Scrape Links with Playwright': False, 'Speak with MacOS TTS': False, 'Evaluate Code': False, 'Analyze Pull Request': False, 'Perform Automated Testing': False, 'Run CI-CD Pipeline': False, 'Improve Code': False, 'Write Tests': False, 'Create a new command': False, 'Execute Task List': False, 'Prompt AI Agent': False, 'Ask AI Agent Bing': False, 'Instruct AI Agent Bing': False, 'Prompt AI Agent Bing': False, 'Ask AI Agent gpt4free': False, 'Instruct AI Agent gpt4free': False, 'Prompt AI Agent gpt4free': False, 'Ask AI Agent Bard': False, 'Instruct AI Agent Bard': False, 'Prompt AI Agent Bard': False, 'Ask AI Agent Vicuna': False, 'Instruct AI Agent Vicuna': False, 'Prompt AI Agent Vicuna': False, 'Ask AI Agent OpenAI': False, 'Instruct AI Agent OpenAI': False, 'Prompt AI Agent OpenAI': False, 'Ask AI Agent azure': False, 'Instruct AI Agent azure': False, 'Prompt AI Agent azure': False, 'Ask AI Agent ChatGPT': False, 'Instruct AI Agent ChatGPT': False, 'Prompt AI Agent ChatGPT': False, 'Ask AI Agent new_agent': False, 'Instruct AI Agent new_agent': False, 'Prompt AI Agent new_agent': False, 'Ask AI Agent Guanaco': False, 'Instruct AI Agent Guanaco': False, 'Prompt AI Agent Guanaco': False, 'Write to File': False, 'Read File': False, 'Search Files': False, 'Append to File': False, 'Execute Python File': False, 'Delete File': False, 'Execute Shell': False, 'Read Audio from File': False, 'Read Audio': False, 'Generate Image with Stable Diffusion': False, 'Speak with TTS with BrianTTS': False, 'Clone Github Repository': False, 'Get Datetime': False, 'Speak with TTS Using Elevenlabs': False, 'Use The Search Engine': False}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_commands()\n",
    "agent_name = \"new_agent\"\n",
    "commands = ApiClient.get_commands(agent_name=agent_name)\n",
    "print(\"Commands:\", commands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toggle a Command for the Agent\n",
    "\n",
    "We'll toggle the `Write to File` command to `true` to confirm that we can toggle a command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toggle command response: Command 'Write to File' toggled for agent 'new_agent'.\n"
     ]
    }
   ],
   "source": [
    "# Test toggle_command()\n",
    "agent_name = \"new_agent\"\n",
    "# We'll enable the \"Write to File\" command for the test\n",
    "toggle_command_resp = ApiClient.toggle_command(\n",
    "    agent_name=agent_name, command_name=\"Write to File\", enable=True\n",
    ")\n",
    "print(\"Toggle command response:\", toggle_command_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat with the Agent\n",
    "\n",
    "We'll chat with the agent to confirm that it is working. We'll ask a simple question like `What is the capital of France?`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: The answer to your question is Paris.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test chat()\n",
    "agent_name = \"new_agent\"\n",
    "chat_resp = ApiClient.chat(\n",
    "    agent_name=agent_name, prompt=\"What is the capital of France?\"\n",
    ")\n",
    "print(\"Chat response:\", chat_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt the Agent\n",
    "\n",
    "Use a custom Prompt Template to prompt the agent. For our example, we'll use our \"Write a Poem\" prompt template to have the agent write a poem for us about dragons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent prompt response: Amidst the fire and smoldering ash,\n",
      "Lies a beast with scales as bright as the ash.\n",
      "\n",
      "Its wings span wide, a sight to behold,\n",
      "As it soars high, unchallenged and bold.\n",
      "\n",
      "A higher power is inside of him,\n",
      "A source of strength that makes the earth dim.\n",
      "\n",
      "His eyes reflect the universe,\n",
      "A journey you'll never know in a hearse.\n",
      "\n",
      "He breathes flames with ecstasy,\n",
      "A power so fatal, a fate full of misery.\n",
      "\n",
      "But in his fierce form and piercing roar,\n",
      "Lies a heart so kind that you'll tear no more.\n",
      "\n",
      "His might may cause fear to arise,\n",
      "But all he wants is to spread love in disguise.\n",
      "\n",
      "Dragons, a mythical creature of might,\n",
      "A symbol of bravery, fearless and bright.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test prompt_agent()\n",
    "agent_name = \"new_agent\"\n",
    "prompt_name = \"Write a Haiku\"\n",
    "user_input = \"Show me 3.\"\n",
    "# The \"Write a Poem\" prompt only requires one argument, \"subject\".\n",
    "# We'll ask the AI to write a poem about dragons.\n",
    "prompt_args = {\"subject\": \"dragons\"}\n",
    "agent_prompt_resp = ApiClient.prompt_agent(\n",
    "    agent_name=agent_name,\n",
    "    prompt_name=prompt_name,\n",
    "    prompt_args=prompt_args,\n",
    "    user_input=user_input,\n",
    "    websearch=False,  # We don't need web search for this test\n",
    "    websearch_depth=0,  # Depth of web search if enabled.\n",
    "    context_results=0,  # Number of context results to inject from memory\n",
    "    shots=1,  # Number of responses to generate\n",
    ")\n",
    "print(\"Agent prompt response:\", agent_prompt_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruct the Agent to do something\n",
    "\n",
    "We'll do something simple with it for the sake of the basic example, we'll just tell it to `Tell me the capital of France`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruct response: The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test instruct()\n",
    "agent_name = \"new_agent\"\n",
    "instruct_resp = ApiClient.instruct(\n",
    "    agent_name=agent_name, prompt=\"Tell me the capital of France.\"\n",
    ")\n",
    "print(\"Instruct response:\", instruct_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat History of the Agent\n",
    "\n",
    "Get the chat history from the Agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat history: [{'USER': 'June 11, 2023 01:55 PM\\nWhat is the capital of France?'}, {'new_agent': 'June 11, 2023 01:55 PM\\nThe answer to your question is Paris.'}, {'USER': 'June 11, 2023 01:55 PM\\n'}, {'new_agent': \"June 11, 2023 01:55 PM\\nAmidst the fire and smoldering ash,\\nLies a beast with scales as bright as the ash.\\n\\nIts wings span wide, a sight to behold,\\nAs it soars high, unchallenged and bold.\\n\\nA higher power is inside of him,\\nA source of strength that makes the earth dim.\\n\\nHis eyes reflect the universe,\\nA journey you'll never know in a hearse.\\n\\nHe breathes flames with ecstasy,\\nA power so fatal, a fate full of misery.\\n\\nBut in his fierce form and piercing roar,\\nLies a heart so kind that you'll tear no more.\\n\\nHis might may cause fear to arise,\\nBut all he wants is to spread love in disguise.\\n\\nDragons, a mythical creature of might,\\nA symbol of bravery, fearless and bright.\"}, {'USER': 'June 11, 2023 01:55 PM\\nTell me the capital of France.'}, {'new_agent': 'June 11, 2023 01:55 PM\\nThe capital of France is Paris.'}]\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_chat_history()\n",
    "agent_name = \"new_agent\"\n",
    "chat_history = ApiClient.get_chat_history(agent_name=agent_name)\n",
    "print(\"Chat history:\", chat_history)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Agent Commands\n",
    "\n",
    "In this example, we'll only change the `Write to File` command to `False`, but we could change any (or all) of the commands with this API call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update agent commands response: Agent new_agent configuration updated.\n",
      "New config for new_agent: {'commands': {'Scrape Text with Playwright': False, 'Scrape Links with Playwright': False, 'Speak with MacOS TTS': False, 'Evaluate Code': False, 'Analyze Pull Request': False, 'Perform Automated Testing': False, 'Run CI-CD Pipeline': False, 'Improve Code': False, 'Write Tests': False, 'Create a new command': False, 'Execute Task List': False, 'Prompt AI Agent': False, 'Ask AI Agent Bing': False, 'Instruct AI Agent Bing': False, 'Prompt AI Agent Bing': False, 'Ask AI Agent gpt4free': False, 'Instruct AI Agent gpt4free': False, 'Prompt AI Agent gpt4free': False, 'Ask AI Agent Bard': False, 'Instruct AI Agent Bard': False, 'Prompt AI Agent Bard': False, 'Ask AI Agent Vicuna': False, 'Instruct AI Agent Vicuna': False, 'Prompt AI Agent Vicuna': False, 'Ask AI Agent OpenAI': False, 'Instruct AI Agent OpenAI': False, 'Prompt AI Agent OpenAI': False, 'Ask AI Agent azure': False, 'Instruct AI Agent azure': False, 'Prompt AI Agent azure': False, 'Ask AI Agent ChatGPT': False, 'Instruct AI Agent ChatGPT': False, 'Prompt AI Agent ChatGPT': False, 'Ask AI Agent new_agent': False, 'Instruct AI Agent new_agent': False, 'Prompt AI Agent new_agent': False, 'Ask AI Agent Guanaco': False, 'Instruct AI Agent Guanaco': False, 'Prompt AI Agent Guanaco': False, 'Write to File': False, 'Read File': False, 'Search Files': False, 'Append to File': False, 'Execute Python File': False, 'Delete File': False, 'Execute Shell': False, 'Read Audio from File': False, 'Read Audio': False, 'Generate Image with Stable Diffusion': False, 'Speak with TTS with BrianTTS': False, 'Clone Github Repository': False, 'Get Datetime': False, 'Speak with TTS Using Elevenlabs': False, 'Use The Search Engine': False}, 'settings': {'AI_MODEL': 'gpt-3.5-turbo', 'AI_TEMPERATURE': 0.5, 'MAX_TOKENS': 4000, 'provider': 'gpt4free'}}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test update_agent_commands()\n",
    "agent_name = \"new_agent\"\n",
    "agent_config = ApiClient.get_agentconfig(agent_name=agent_name)\n",
    "agent_commands = agent_config[\"commands\"]\n",
    "agent_commands[\"Write to File\"] = False\n",
    "update_agent_commands_resp = ApiClient.update_agent_commands(\n",
    "    agent_name=agent_name, commands=agent_commands\n",
    ")\n",
    "print(\"Update agent commands response:\", update_agent_commands_resp)\n",
    "agent_config = ApiClient.get_agentconfig(agent_name=agent_name)\n",
    "print(f\"New config for {agent_name}:\", agent_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have the Agent Learn from a File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Learning response: Agent learned the content from the file.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test learn_file()\n",
    "agent_name = \"new_agent\"\n",
    "file_learning = ApiClient.learn_file(\n",
    "    agent_name=agent_name, file_name=\"test.txt\", file_content=\"This is a test file.\"\n",
    ")\n",
    "print(\"File Learning response:\", file_learning)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have the Agent Learn from a URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Learning response: Agent learned the content from the url.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test learn_url()\n",
    "agent_name = \"new_agent\"\n",
    "url_learning = ApiClient.learn_url(agent_name=agent_name, url=\"https://agixt.com\")\n",
    "print(\"URL Learning response:\", url_learning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wipe the agents memories\n",
    "\n",
    "This is necessary if you want the agent to serve a different purpose than its original intent after it has learned things. It may inject unnecessary context into the conversation if you don't wipe its memory and try to give it a different purpose, even temporarily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wipe agent memories response: Memories for agent new_agent deleted.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test wipe_agent_memories()\n",
    "# Note: Use this function with caution as it will erase the agent's memory.\n",
    "agent_name = \"new_agent\"\n",
    "wipe_mem_resp = ApiClient.wipe_agent_memories(agent_name=agent_name)\n",
    "print(\"Wipe agent memories response:\", wipe_mem_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of Chains available to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chains: ['Smart Instruct', 'Test_Commands', 'Write a Poem', 'Smart Chat', 'Task']\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_chains()\n",
    "chains = ApiClient.get_chains()\n",
    "print(\"Chains:\", chains)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add chain response: Chain 'Write another Poem' created.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test add_chain()\n",
    "chain_name = \"Write another Poem\"\n",
    "add_chain_resp = ApiClient.add_chain(chain_name=chain_name)\n",
    "print(\"Add chain response:\", add_chain_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename chain response: Chain 'Write another Poem' renamed to 'Poem Writing Chain'.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test rename_chain()\n",
    "chain_name = \"Write another Poem\"\n",
    "new_chain_name = \"Poem Writing Chain\"\n",
    "rename_chain_resp = ApiClient.rename_chain(\n",
    "    chain_name=chain_name, new_name=new_chain_name\n",
    ")\n",
    "print(\"Rename chain response:\", rename_chain_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Chain Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add step response: Step 1 added to chain 'Poem Writing Chain'.\n",
      "Add step response: Step 2 added to chain 'Poem Writing Chain'.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "agent_name = \"new_agent\"\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "# Test add_step()\n",
    "add_step_resp = ApiClient.add_step(\n",
    "    chain_name=chain_name,\n",
    "    step_number=1,\n",
    "    agent_name=agent_name,\n",
    "    prompt_type=\"Prompt\",\n",
    "    prompt={\n",
    "        \"prompt_name\": \"Write a Poem\",\n",
    "        \"subject\": \"Artificial Intelligence\",\n",
    "    },\n",
    ")\n",
    "print(\"Add step response:\", add_step_resp)\n",
    "add_step_resp = ApiClient.add_step(\n",
    "    chain_name=chain_name,\n",
    "    step_number=2,\n",
    "    agent_name=agent_name,\n",
    "    prompt_type=\"Prompt\",\n",
    "    prompt={\n",
    "        \"prompt_name\": \"Write a Poem\",\n",
    "        \"subject\": \"Quantum Computers\",\n",
    "    },\n",
    ")\n",
    "print(\"Add step response:\", add_step_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the content of the chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain: {'chain_name': 'Poem Writing Chain', 'steps': [{'step': 1, 'agent_name': 'new_agent', 'prompt_type': 'Prompt', 'prompt': {'prompt_name': 'Write a Poem', 'subject': 'Artificial Intelligence'}}, {'step': 2, 'agent_name': 'new_agent', 'prompt_type': 'Prompt', 'prompt': {'prompt_name': 'Write a Poem', 'subject': 'Quantum Computers'}}]}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_chain()\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "chain = ApiClient.get_chain(chain_name=chain_name)\n",
    "print(\"Chain:\", chain)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify a chain step\n",
    "\n",
    "Instead of the subject of the poem just being Artificial Intelligence, we'll change it to be Artificial General Intelligence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update step response: Step 1 updated for chain 'Poem Writing Chain'.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "agent_name = \"new_agent\"\n",
    "# Test update_step()\n",
    "update_step_resp = ApiClient.update_step(\n",
    "    chain_name=chain_name,\n",
    "    step_number=1,\n",
    "    agent_name=agent_name,\n",
    "    prompt_type=\"Prompt\",\n",
    "    prompt={\n",
    "        \"prompt_name\": \"Write a Poem\",\n",
    "        \"subject\": \"Artificial General Intelligence\",\n",
    "    },\n",
    ")\n",
    "print(\"Update step response:\", update_step_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move the chain step\n",
    "\n",
    "When you move a step, it will automatically reassign the order of the steps to match the new order. If there are only 2 steps like in our case, it will just swap them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Move step response: Step 1 moved to 2 in chain 'Poem Writing Chain'.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "agent_name = \"new_agent\"\n",
    "\n",
    "# Test move_step()\n",
    "move_step_resp = ApiClient.move_step(\n",
    "    chain_name=chain_name, old_step_number=1, new_step_number=2\n",
    ")\n",
    "print(\"Move step response:\", move_step_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a Command to the Chain\n",
    "\n",
    "We'll write the result to a file for an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add step response: Step 3 added to chain 'Poem Writing Chain'.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "agent_name = \"new_agent\"\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "# Test add_step()\n",
    "add_step_resp = ApiClient.add_step(\n",
    "    chain_name=chain_name,\n",
    "    step_number=3,\n",
    "    agent_name=agent_name,\n",
    "    prompt_type=\"Command\",\n",
    "    prompt={\n",
    "        \"command_name\": \"Write to File\",\n",
    "        \"filename\": \"{user_input}.txt\",\n",
    "        \"text\": \"First Poem:\\n{STEP1}\\n\\nSecond Poem:\\n{STEP2}\",\n",
    "    },\n",
    ")\n",
    "print(\"Add step response:\", add_step_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# The user input for this chain will just be the name of the text file to write to.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m user_input \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSuper Poems\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m run_chain_resp \u001b[39m=\u001b[39m ApiClient\u001b[39m.\u001b[39;49mrun_chain(chain_name\u001b[39m=\u001b[39;49mchain_name, user_input\u001b[39m=\u001b[39;49muser_input)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRun chain response:\u001b[39m\u001b[39m\"\u001b[39m, run_chain_resp)\n",
      "File \u001b[0;32m~/josh/Repos/AGiXT/tests/ApiClient.py:201\u001b[0m, in \u001b[0;36mApiClient.run_chain\u001b[0;34m(chain_name, user_input)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_chain\u001b[39m(chain_name: \u001b[39mstr\u001b[39m, user_input: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 201\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m    202\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mbase_uri\u001b[39m}\u001b[39;49;00m\u001b[39m/api/chain/\u001b[39;49m\u001b[39m{\u001b[39;49;00mchain_name\u001b[39m}\u001b[39;49;00m\u001b[39m/run\u001b[39;49m\u001b[39m\"\u001b[39;49m, json\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: user_input}\n\u001b[1;32m    203\u001b[0m     )\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test run_chain()\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "# The user input for this chain will just be the name of the text file to write to.\n",
    "user_input = \"Super Poems\"\n",
    "run_chain_resp = ApiClient.run_chain(chain_name=chain_name, user_input=user_input)\n",
    "print(\"Run chain response:\", run_chain_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the responses from the chain running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain: {'1': {'response': \"Quantum Computers, oh how they compute,\\nBits of information, not just zero or one to compute,\\nIn superposition, they store and calculate,\\nQuantum mechanics, truly an amazing state.\\n\\nWith qubits, they can solve tough tasks with ease,\\nStructure of molecules, or prime number keys,\\nSecurity and simulations, oh what a feat,\\nQuantum supremacy, yet to be fully complete.\\n\\nEntanglement, a mystery to unfold,\\nInstantaneous connection, or so we are told,\\nQuantum teleportation, not as sci-fi as it seems,\\nPossibilities, endless like virtual reality dreams.\\n\\nQuantum Computers, a new era in sight,\\nA digital revolution, a paradigm shift in sight,\\nFrom biology to finance, they'll change the game,\\nWith Quantum Computing, we'll never be the same.\", 'agent_name': 'new_agent', 'prompt': {'prompt_name': 'Write a Poem', 'subject': 'Quantum Computers'}, 'prompt_type': 'Prompt'}, '2': {'response': \"Artificial general intelligence,\\nA concept that we can't ignore,\\nIt's the future of technology,\\nAdvanced and smart forevermore.\\n\\nA.I. that's more than just one task,\\nIt thinks and learns like we do,\\nAdapting to every situation,\\nAnd solving problems anew.\\n\\nIt'll act as our personal assistant,\\nHelping us with our daily routine,\\nFrom booking tickets to cooking food,\\nIt'll do tasks that seem routine.\\n\\nAnd as it continues to evolve,\\nIt'll make our lives better and brighter,\\nWith more creativity and innovation,\\nThe future's looking even tighter.\\n\\nSo let's embrace this A.I. phenomenon,\\nAnd marvel at its incredible power,\\nFor it's the future we must all prepare for,\\nIn this ever-changing technological hour.\", 'agent_name': 'new_agent', 'prompt': {'prompt_name': 'Write a Poem', 'subject': 'Artificial General Intelligence'}, 'prompt_type': 'Prompt'}, '3': {'response': 'File written to successfully.', 'agent_name': 'new_agent', 'prompt': {'command_name': 'Write to File', 'filename': '{user_input}.txt', 'text': 'First Poem:\\n{STEP1}\\n\\nSecond Poem:\\n{STEP2}'}, 'prompt_type': 'Command'}}\n"
     ]
    }
   ],
   "source": [
    "# Need to make a function to get_chain_responses() as it's not in the API yet.\n",
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_chain()\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "chain = ApiClient.get_chain_responses(chain_name=chain_name)\n",
    "print(\"Chain:\", chain)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete a step from the chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete step response: Step 2 deleted from chain 'Poem Writing Chain'.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test delete_step()\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "delete_step_resp = ApiClient.delete_step(chain_name=chain_name, step_number=2)\n",
    "print(\"Delete step response:\", delete_step_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete chain response: Chain 'Poem Writing Chain' deleted.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test delete_chain()\n",
    "chain_name = \"Poem Writing Chain\"\n",
    "delete_chain_resp = ApiClient.delete_chain(chain_name=chain_name)\n",
    "print(\"Delete chain response:\", delete_chain_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts\n",
    "\n",
    "## Get a list of prompts available to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts: ['Pseudo Code', 'SmartInstruct-Researcher', 'Custom Input', 'Title a Poem', 'ValidationFailed', 'SmartTask-CleanResponse', 'SmartChat-Researcher', 'Tell Me How', 'Execution', 'Score Response', 'Validation', 'Write a Haiku', 'SmartInstruct-Resolver', 'SmartInstruct-CleanResponse', 'SmartInstruct-StepByStep', 'instruct', 'Pick a Poem Subject', 'Task Execution', 'Check-Instruction', 'SmartTask-Execution', 'SmartChat-Resolver', 'Chat', 'Create New Command', 'SmartChat-CleanResponse', 'Prioritize', 'Pick-a-Link', 'SmartInstruct-Execution', 'Write a Poem', 'JSONFormatter', 'SmartTask-StepByStep', 'Instruction', 'WebSearch', 'SmartChat-StepByStep', 'Get Task List']\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_prompts()\n",
    "prompts = ApiClient.get_prompts()\n",
    "print(\"Prompts:\", prompts)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new prompt\n",
    "\n",
    "We'll make a basic prompt that asks the AI to tell us a short story about a subject. The subject is not yet defined, it would be defined in a chain. Using `{variable_name}` in a prompt will allow you to define the variable in a chain and have it be used in the prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add prompt response: Prompt 'Short Story' added.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test add_prompt()\n",
    "add_prompt_resp = ApiClient.add_prompt(\n",
    "    prompt_name=\"Short Story\", prompt=\"Tell me a short story about {subject}\"\n",
    ")\n",
    "print(\"Add prompt response:\", add_prompt_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the prompt content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get prompt response: Write a poem about {subject} .\n",
      "{user_input}\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_prompt()\n",
    "get_prompt_resp = ApiClient.get_prompt(prompt_name=\"Write a Poem\")\n",
    "print(\"Get prompt response:\", get_prompt_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the prompt variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get prompt args response: ['subject']\n"
     ]
    }
   ],
   "source": [
    "# Get prompt args\n",
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test get_prompt_args()\n",
    "get_prompt_args_resp = ApiClient.get_prompt_args(prompt_name=\"Short Story\")\n",
    "print(\"Get prompt args response:\", get_prompt_args_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the prompt content\n",
    "\n",
    "We'll ask it to `Add a dragon to the story somehow` in the prompt to make the short story more interesting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update prompt response: Prompt 'Short Story' updated.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test update_prompt()\n",
    "update_prompt_resp = ApiClient.update_prompt(\n",
    "    prompt_name=\"Short Story\",\n",
    "    prompt=\"Tell me a short story about {subject}. Add a dragon to the story somehow.\",\n",
    ")\n",
    "print(\"Update prompt response:\", update_prompt_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the prompt\n",
    "\n",
    "If you don't want the prompt anymore, delete it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete prompt response: Prompt 'Short Story' deleted.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test delete_prompt()\n",
    "delete_prompt_resp = ApiClient.delete_prompt(prompt_name=\"Short Story\")\n",
    "print(\"Delete prompt response:\", delete_prompt_resp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Agent History\n",
    "\n",
    "Delete the history for the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete agent response: History for agent new_agent deleted.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test delete_agent()\n",
    "agent_name = \"new_agent\"\n",
    "delete_agent_resp = ApiClient.delete_agent_history(agent_name=agent_name)\n",
    "print(\"Delete agent response:\", delete_agent_resp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the Agent\n",
    "\n",
    "If you are done with the agent and don't want or need it anymore, you can delete it along with everything associated with it, such as its memories, settings, and history. The Agent isn't just fired, it is dead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete agent response: Agent new_agent deleted.\n"
     ]
    }
   ],
   "source": [
    "from ApiClient import ApiClient\n",
    "\n",
    "# Test delete_agent()\n",
    "agent_name = \"new_agent\"\n",
    "delete_agent_resp = ApiClient.delete_agent(agent_name=agent_name)\n",
    "print(\"Delete agent response:\", delete_agent_resp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
